{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc7iPvhCO4+Ag/ar8QRad1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazbi123/koudoB/blob/main/koudoB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "本当は低評価数もあれば比較しやすかったかも\n",
        "\n",
        "shiftjis\n",
        "\n",
        "使った辞書がネガティブワードの方が多い\n",
        "\n",
        "good 同調のため符号変化なし\n",
        "reply 反対意見で多くなっている場合もあるので符号変化させる必要あり\n"
      ],
      "metadata": {
        "id": "s5h0vCcw12aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!wget \"http://www.lr.pi.titech.ac.jp/~takamura/pubs/pn_ja.dic\"\n",
        "!wget 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
        "!apt-get -y install fonts-ipafont-gothic\n",
        "!pip install mecab-python3 unidic-lite\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "import MeCab\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "#画像に文字を挿入するとき場所を指定する関数\n",
        "def put_text_in_image(img, text, place = 'bottom-right', size = 1, color = 'black', thickness = 2, margin = 5, bordering = None):\n",
        "    \"\"\"\n",
        "    画像に文字を入れる\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    img : np.array\n",
        "        文字を入れたい画像イメージ（cv2形式）\n",
        "\n",
        "    text : str\n",
        "        入れたい文字列（英数字のみ）\n",
        "\n",
        "    place : str\n",
        "        'top' : 上部中央\n",
        "        'top-left' : 上部左寄せ\n",
        "        'top-right' : 上部右寄せ\n",
        "        'center' : 中央\n",
        "        'bottom' : 下部中央\n",
        "        'bottom-left' : 下部左寄せ\n",
        "        'bottom-right' : 下部右寄せ\n",
        "\n",
        "    size : float\n",
        "        フォントサイズ\n",
        "\n",
        "    color : str\n",
        "        文字色。['black', 'red', 'blue', 'green', 'orange', 'yellow', 'white']のいずれか\n",
        "\n",
        "    thickness : int > 0\n",
        "        フォントの太さ\n",
        "\n",
        "    margin : int\n",
        "        余白の大きさ\n",
        "\n",
        "    bordering : dic\n",
        "        縁取りしたい時に指定する\n",
        "        'color' : 縁取りの色\n",
        "        'thickness' : 縁取りの太さ\n",
        "\n",
        "    return : np.array\n",
        "        ウィンドウの画像イメージ（cv2形式）\n",
        "        ウィンドウが見つからなかった場合はNoneを返す\n",
        "    \"\"\"\n",
        "    # textをstrに変換\n",
        "    text = str(text)\n",
        "    # 文字の大きさを取得する\n",
        "    # 黒バックの仮画像を生成\n",
        "    height = int(50*size)\n",
        "    width = int(len(text)*20*size + 10 + thickness - 1)\n",
        "    blank = np.zeros((height, width, 3))\n",
        "    # 黒バックに白で文字を入れる\n",
        "    top, bottom, left, right = [0,0,0,0]\n",
        "    cv2.putText(blank, text, (10,int(height/2)), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = size, color = (255,255,255), thickness=thickness)\n",
        "    # 単純な2次元配列に落とす\n",
        "    temp = np.array([[int(j[0]) for j in i] for i in blank])\n",
        "    # 文字がある上限を検索\n",
        "\n",
        "    for i in range(height):\n",
        "        if 255 in temp[i]:\n",
        "            top = i\n",
        "            break\n",
        "\n",
        "    # 文字がある下限を検索\n",
        "    for i in reversed(range(height)):\n",
        "        if 255 in temp[i]:\n",
        "            bottom = i\n",
        "            break\n",
        "\n",
        "    # 文字がある左限を検索\n",
        "    for i in range(width):\n",
        "        if 255 in temp[:,i]:\n",
        "            left = i\n",
        "            break\n",
        "\n",
        "    # 文字がある右限を検索\n",
        "    for i in reversed(range(width)):\n",
        "        if 255 in temp[:,i]:\n",
        "            right = i\n",
        "            break\n",
        "\n",
        "    # 描画開始位置の左限と実際のピクセル左限との差\n",
        "    left_diff = left - 10\n",
        "    # 描画開始位置の下限と実際のピクセル下限との差\n",
        "    bottom_diff = bottom - int(height/2)\n",
        "    # 文字を置く座標を算出\n",
        "    height, width = img.shape[:2]\n",
        "    text_height, text_width = [bottom-top, right-left]\n",
        "    loc = (0,0)\n",
        "\n",
        "    if place == 'top':\n",
        "        loc = (width/2 - text_width/2, text_height + margin - size*7)\n",
        "\n",
        "    elif place == 'top-left':\n",
        "        loc = (margin, text_height + margin - size*7)\n",
        "\n",
        "    elif place == 'top-right':\n",
        "        loc = (width - text_width - margin + left_diff, text_height + margin - size*7)\n",
        "\n",
        "    elif place == 'center':\n",
        "        loc = (width/2 - text_width/2, height/2 - text_height/2+25)\n",
        "\n",
        "    elif place == 'bottom':\n",
        "        loc = (width/2 - text_width/2, height - margin - bottom_diff)\n",
        "\n",
        "    elif place == 'bottom-left':\n",
        "        loc = (margin, height - margin - bottom_diff)\n",
        "\n",
        "    elif place == 'bottom-right':\n",
        "        loc = (width - text_width - margin + left_diff, height - margin - bottom_diff)\n",
        "\n",
        "    # 座標を整数値化\n",
        "    loc = [int(i) for i in loc]\n",
        "    # 色を指定\n",
        "    color_BGR = {\n",
        "        'black' : (0,0,0),\n",
        "        'red' : (0,0,255),\n",
        "        'blue' : (255,0,0),\n",
        "        'green' : (0,255,0),\n",
        "        'orange' : (0,127,255),\n",
        "        'yellow' : (0,255,255),\n",
        "        'white' : (255,255,255),\n",
        "    }\n",
        "    col=color\n",
        "    text_img = img.copy()\n",
        "\n",
        "    # 縁取り\n",
        "    if bordering:\n",
        "        cv2.putText(text_img, text, loc, fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = size, color = color_BGR[bordering['color']], thickness=thickness + bordering['thickness'])\n",
        "    cv2.putText(text_img, text, loc, fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = size, color = col, thickness=thickness)\n",
        "    return text_img\n",
        "\n",
        "#ポジティブ、ネガティブの点数を読み込む\n",
        "pn_df=pd.read_csv('/content/pn_ja.dic',sep=':',encoding='shift_jis',names=('Word','Reading','POS', 'PN'))\n",
        "#日本語のストップワードを読み込む\n",
        "stop=pd.read_csv(\"Japanese.txt\",encoding='utf-8',names=('i','e'))\n",
        "#日本語のストップワードをリストに\n",
        "stop=list(stop['i'])\n",
        "#ポジティブ、ネガティブの辞書をリストに\n",
        "word_list = list(pn_df['Word'])\n",
        "pn_list = list(pn_df['PN'])  # 中身の型はnumpy.float64\n",
        "pn_dict = dict(zip(word_list, pn_list))\n",
        "#ようつべAPI\n",
        "URL = 'https://www.googleapis.com/youtube/v3/'\n",
        "API_KEY = 'API key'\n",
        "#リストの初期設定\n",
        "\n",
        "comments=[]\n",
        "reply=[]\n",
        "good=[]\n",
        "koubun=[]\n",
        "diclist_new=[]\n",
        "pn_all=[]\n",
        "text_list=[]\n",
        "new=[]\n",
        "\n",
        "#ようつべからコメント、返信、いいねを読み込む関数\n",
        "def print_video_comment(video_id, next_page_token):\n",
        "  params = {\n",
        "    'key': API_KEY,\n",
        "    'part': 'snippet',\n",
        "    'videoId': video_id,\n",
        "    'order': 'relevance',\n",
        "    'textFormat': 'plaintext',\n",
        "    'maxResults': 100,\n",
        "  }\n",
        "  if next_page_token is not None:\n",
        "    params['pageToken'] = next_page_token\n",
        "  response = requests.get(URL + 'commentThreads', params=params)\n",
        "  resource = response.json()\n",
        "  for comment_info in resource['items']:\n",
        "    text = comment_info['snippet']['topLevelComment']['snippet']['textDisplay'] # コメント\n",
        "    like_cnt = comment_info['snippet']['topLevelComment']['snippet']['likeCount'] # グッド数\n",
        "    reply_cnt = comment_info['snippet']['totalReplyCount'] # 返信数\n",
        "\n",
        "    #それぞれをリストに入れていく\n",
        "    comments.append(text.replace('\\r', ' ').replace('\\n',' '))\n",
        "    reply.append(reply_cnt)\n",
        "    good.append(like_cnt)\n",
        "  # with open(\"/content/comment.txt\",\"w\") as f1:\n",
        "  #   f1.write(\"\\n\".join(comments))\n",
        "\n",
        "  if 'nextPageToken' in resource:\n",
        "    print_video_comment(video_id, resource[\"nextPageToken\"])\n",
        "\n",
        "#URLを入力し正規表現でIDを取る\n",
        "video_id=re.findall(r\"watch\\?v\\=(.*)\",input(\"URL?\"))[0]\n",
        "\n",
        "#関数実行\n",
        "print_video_comment(video_id, None)\n",
        "# with open(\"/content/comment.txt\",\"r\") as f2:\n",
        "#   text=f2.read()\n",
        "# print(text)\n",
        "#形態素解析\n",
        "\n",
        "for text in comments:\n",
        "  text = re.sub('https:\\/\\/[\\w\\/\\.]+', '', text)\n",
        "  node = MeCab.Tagger().parse(text)\n",
        "  lines=re.split(\"\\n\",node)\n",
        "  lines=lines[0:-2]\n",
        "  text_list.append(lines)\n",
        "\n",
        "#形態素解析の結果を品詞などに分けて辞書化\n",
        "for i in text_list:\n",
        "\n",
        "  for text2 in i:\n",
        "    l = re.split('\\t|,',text2)\n",
        "    d={'Surface':l[0], 'POS1':l[4], 'POS2':l[5], 'BaseForm':l[3]}\n",
        "    new.append(d)\n",
        "  koubun.append(new)\n",
        "  new=[]\n",
        "\n",
        "#ポジティブのリストと比較\n",
        "for i in koubun:\n",
        "\n",
        "  for word in i:\n",
        "    base=word['BaseForm']\n",
        "\n",
        "    if base in pn_dict:\n",
        "        pn = float(pn_dict[base])  # 中身の型があれなので\n",
        "\n",
        "    else:\n",
        "        pn = 'notfound'\n",
        "\n",
        "    word['PN'] = pn\n",
        "    #次のワードクラウドのためにテキストを準備\n",
        "\n",
        "    if word['POS1'].startswith((\"名詞\", \"形容詞\", \"動詞\", \"副詞\")):\n",
        "      diclist_new.append(word['BaseForm'])\n",
        "\n",
        "diclist_new= ' '.join(diclist_new)\n",
        "#ポジティブ化の点数をリストにアペンド\n",
        "a=[]\n",
        "\n",
        "for i in koubun:\n",
        "\n",
        "  for word in i:\n",
        "    pn=word['PN']\n",
        "\n",
        "    if pn!='notfound':\n",
        "      a.append(pn)\n",
        "\n",
        "  pn_all.append(a)\n",
        "  a=[]\n",
        "#コメントごとの平均値をとる。ただし±0.1の範囲は0\n",
        "pnmean_all=[]\n",
        "\n",
        "for i in pn_all:\n",
        "\n",
        "  if len(i) > 0:        # 「全部notfound」じゃなければ\n",
        "    pnmean = sum(i)/len(i)\n",
        "\n",
        "    if pnmean>=0.1:\n",
        "      pnmean=1\n",
        "\n",
        "    elif pnmean<=-0.1:\n",
        "      pnmean=-1\n",
        "\n",
        "    else:\n",
        "      pnmean=0\n",
        "\n",
        "    pnmean_all.append(pnmean)\n",
        "\n",
        "  else:\n",
        "    pnmean=0\n",
        "    pnmean_all.append(pnmean)\n",
        "\n",
        "#グッドの数を平均からどれだけ離れているかを使って2までの数に\n",
        "max_good=max(good)\n",
        "\n",
        "for i in range(len(good)):\n",
        "  good[i]=good[i]/max_good+1\n",
        "\n",
        "#評価にいいねの数をかけて何倍かにする\n",
        "eva=np.array(pnmean_all)*np.array(good)\n",
        "#それの平均値\n",
        "eva_ave=sum(eva)/len(eva)\n",
        "g_or_b=''\n",
        "#視覚的にわかるように\n",
        "#-sqrt3<=sqrt3\n",
        "\n",
        "if eva_ave>0:\n",
        "  r=int((127/(3**(1/2)))*(eva_ave)+128)\n",
        "  g=255-r\n",
        "\n",
        "  if eva_ave>=0.1:\n",
        "    g_or_b='good'\n",
        "\n",
        "  else:\n",
        "    g_or_b='average'\n",
        "\n",
        "elif eva_ave<0:\n",
        "  g=int((127/(3**(1/2)))*(-eva_ave)+128)\n",
        "  r=255-g\n",
        "\n",
        "  if eva_ave<=-0.1:\n",
        "    g_or_b='bad'\n",
        "\n",
        "  else:\n",
        "    g_or_b='average'\n",
        "\n",
        "else:\n",
        "  r=128\n",
        "  g=128\n",
        "  g_or_b='average'\n",
        "\n",
        "#評価結果の画像を作成\n",
        "img = np.zeros( (240,320,3), np.uint8 )\n",
        "cv2.rectangle(img,pt1=(0,0),pt2=(320,240),color=(128,g,r),thickness=-1,lineType=cv2.LINE_4,shift=0)\n",
        "cv2.circle(img,center=(160, 120),radius=100,color=(255, 255,255),thickness=-1,lineType=cv2.LINE_4,shift=0)\n",
        "img=put_text_in_image(img,g_or_b, place='center', size=1.5, color = (128,g,r), thickness=3, margin=10)\n",
        "\n",
        "# ストップワードの設定\n",
        "#英語のストップワードのダウンロード\n",
        "nltk.download('stopwords')\n",
        "stop_words = [ u'てる', u'いる', u'なる', u'れる', u'する', u'ある', u'こと', u'これ', u'さん', u'して', \\\n",
        "             u'くれる', u'やる', u'くださる', u'そう', u'せる', u'した',  u'思う',  \\\n",
        "             u'それ', u'ここ', u'ちゃん', u'くん', u'', u'て',u'に',u'を',u'は',u'の', u'が', u'と', u'た', u'し', u'で', \\\n",
        "             u'ない', u'も', u'な', u'い', u'か', u'ので', u'よう', u'', u'a', u'an', u'the', u'this', u'that', u'and', u'or'\\\n",
        "             u'at',u'you',u'we',u'they',u'to',u'at',u'it',u'with',u'of',u'so',u'for',u'your',u'is',u'new',u'be',u'always',u'為る',u'Hey',u'song',u'再生',u'曲',u'聞く',u'成る'] #定番のストップワード\n",
        "stop_words += stopwords.words('english')\n",
        "stop_words+=stop\n",
        "#ワードクラウドの画像生成\n",
        "wordcloud = WordCloud(font_path = '/usr/share/fonts/truetype/fonts-japanese-mincho.ttf',\n",
        "                      background_color=\"white\",\n",
        "                      width=960,height=720,\n",
        "                      stopwords=set(stop_words)).generate(diclist_new)\n",
        "\n",
        "#表として上2つと、コメント数といいねの平均を\n",
        "fig = plt.figure(figsize=(20,16))\n",
        "fig.suptitle('WordCloud & Sentiment Analysis')\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(good)\n",
        "plt.ylabel('average')\n",
        "plt.xlabel('number of people')\n"
      ],
      "metadata": {
        "id": "PdXAjqzi1Sp9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}